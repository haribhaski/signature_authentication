{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4FLOHBYga-qj"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow import keras\n","import numpy as np\n","import os\n","from IPython.display import display, Javascript\n","import io\n","import base64\n","import cv2\n","from tensorflow.keras import backend as K\n","from PIL import Image\n","from google.colab import output\n","import google.colab\n","\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator,img_to_array, load_img, save_img\n","from tensorflow.keras.models import Sequential,load_model\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense,Dropout,BatchNormalization"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"41zU7z7qCE52","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720106912142,"user_tz":-330,"elapsed":22831,"user":{"displayName":"Hariharan Bhaskaran","userId":"14226885344040727414"}},"outputId":"ab50379a-7558-4470-c52b-33ba0fec7608"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"]},{"cell_type":"code","source":["train_dir = '/content/drive/MyDrive/Signature recognition'\n"],"metadata":{"id":"ClU8U4lcLs5q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Function to count images in each subfolder\n","def count_images_in_subfolders(directory):\n","    global imcount\n","    for user in os.listdir(directory):\n","        user_dir = os.path.join(directory, user)\n","        if os.path.isdir(user_dir):\n","            image_count = int(len([img for img in os.listdir(user_dir) if img.endswith(('.png', '.jpg', '.jpeg'))]))\n","            print(f\"User '{user}' has {image_count} images\")\n","            imcount+=image_count\n","    print(f\"Total images in all users: {imcount}\")\n","\n","# Count and print the number of images in each subfolder\n","imcount=0\n","\n","count_images_in_subfolders(train_dir)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5AQb-2cWGn8A","executionInfo":{"status":"ok","timestamp":1720107017925,"user_tz":-330,"elapsed":454,"user":{"displayName":"Hariharan Bhaskaran","userId":"14226885344040727414"}},"outputId":"2db55e91-b0bb-4aa8-9355-0a6083daf4b6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["User 'bhaski' has 22 images\n","User 'Barani' has 22 images\n","User 'Hariharan' has 22 images\n","Total images in all users: 66\n"]}]},{"cell_type":"code","source":["\n","#. DO  NOT. RUN. THIS. OR. YOU WILL DIE (I better die)\n","\n","import os\n","import base64\n","import io\n","from PIL import Image\n","import numpy as np\n","from IPython.display import display, Javascript\n","import google.colab.output\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, save_img\n","\n","train_dir = '/content/drive/MyDrive/Signature recognition'\n","\n","def preprocess_image(image_data):\n","    image = Image.open(io.BytesIO(image_data))\n","    image = image.convert('L')  # Convert to grayscale\n","    image = image.resize((28, 28))  # Resize to model input size\n","    img_array = np.array(image) / 255.0  # Normalize to [0, 1]\n","    img_array = np.expand_dims(img_array, axis=(0, -1))  # Add batch and channel dimensions\n","    return img_array\n","\n","def add_subdir(data_url):\n","    global userName\n","    global signatureCount\n","\n","    # Decode base64 image data\n","    image_data = base64.b64decode(data_url.split(',')[1])\n","    # Preprocess the image\n","    img_array = preprocess_image(image_data)\n","\n","    # Save the image to the user's directory\n","    user_dir = os.path.join(train_dir, userName)\n","    if not os.path.exists(user_dir):\n","        os.makedirs(user_dir)\n","    img_path = os.path.join(user_dir, f'signature_{signatureCount}.png')\n","    save_image(img_array, img_path)\n","    print(f\"Signature saved to {img_path}\")\n","\n","    signatureCount += 1  # Increment the count for the next image\n","\n","    # Perform augmentation after the second signature is saved\n","    if signatureCount > 2:\n","        augment_images_for_user(user_dir)\n","\n","def save_image(img_array, path):\n","    image = Image.fromarray((img_array.squeeze() * 255).astype(np.uint8))\n","    image.save(path)\n","\n","def augment_images_for_user(user_dir):\n","    # ImageDataGenerator for data augmentation\n","    datagen = ImageDataGenerator(\n","        rotation_range=10,\n","        width_shift_range=0.1,\n","        height_shift_range=0.1,\n","        shear_range=0.1,\n","        zoom_range=0.1,\n","        fill_mode='nearest',\n","        brightness_range=[0.8, 1.2],\n","        channel_shift_range=0.1\n","    )\n","\n","    # Number of augmented images per original image\n","    num_augmented_images = 10\n","\n","    # Loop through each image in the user's directory\n","    for img_name in os.listdir(user_dir):\n","        img_path = os.path.join(user_dir, img_name)\n","        if os.path.isfile(img_path) and img_name.endswith(('.png', '.jpg', '.jpeg', '.png')):\n","            # Load the image\n","            img = load_img(img_path, color_mode='grayscale')\n","            x = img_to_array(img)\n","            x = np.expand_dims(x, axis=0)\n","\n","            # Create augmented images and save them\n","            i = 0\n","            for batch in datagen.flow(x, batch_size=1):\n","                i += 1\n","                save_img(os.path.join(user_dir, f'aug_{i}_{img_name}'), batch[0])\n","                if i >= num_augmented_images:\n","                    break\n","\n","DRAW_JS_1 = \"\"\"\n","const canvas1 = document.createElement('canvas');\n","canvas1.width = 400;\n","canvas1.height = 200;\n","canvas1.style.border = '1px solid black';\n","document.body.appendChild(canvas1);\n","\n","const ctx1 = canvas1.getContext('2d');\n","ctx1.fillStyle = 'white';\n","ctx1.fillRect(0, 0, canvas1.width, canvas1.height);\n","\n","canvas1.onmousedown = function(e) {\n","  ctx1.beginPath();\n","  ctx1.moveTo(e.offsetX, e.offsetY);\n","  canvas1.onmousemove = function(e) {\n","    ctx1.lineTo(e.offsetX, e.offsetY);\n","    ctx1.stroke();\n","  };\n","};\n","\n","canvas1.onmouseup = function() {\n","  canvas1.onmousemove = null;\n","};\n","\n","const saveButton1 = document.createElement('button');\n","saveButton1.innerHTML = 'Save Signature 1';\n","saveButton1.onclick = function() {\n","  const dataURL = canvas1.toDataURL('image/png');\n","  google.colab.kernel.invokeFunction('notebook.add_subdir', [dataURL], {});\n","};\n","document.body.appendChild(saveButton1);\n","\"\"\"\n","\n","DRAW_JS_2 = \"\"\"\n","const canvas2 = document.createElement('canvas');\n","canvas2.width = 400;\n","canvas2.height = 200;\n","canvas2.style.border = '1px solid black';\n","document.body.appendChild(canvas2);\n","\n","const ctx2 = canvas2.getContext('2d');\n","ctx2.fillStyle = 'white';\n","ctx2.fillRect(0, 0, canvas2.width, canvas2.height);\n","\n","canvas2.onmousedown = function(e) {\n","  ctx2.beginPath();\n","  ctx2.moveTo(e.offsetX, e.offsetY);\n","  canvas2.onmousemove = function(e) {\n","    ctx2.lineTo(e.offsetX, e.offsetY);\n","    ctx2.stroke();\n","  };\n","};\n","\n","canvas2.onmouseup = function() {\n","  canvas2.onmousemove = null;\n","};\n","\n","const saveButton2 = document.createElement('button');\n","saveButton2.innerHTML = 'Save Signature 2';\n","saveButton2.onclick = function() {\n","  const dataURL = canvas2.toDataURL('image/png');\n","  google.colab.kernel.invokeFunction('notebook.add_subdir', [dataURL], {});\n","};\n","document.body.appendChild(saveButton2);\n","\"\"\"\n","\n","def new_user_reg(name):\n","    global userName\n","    global signatureCount\n","\n","    user_dir = os.path.join(train_dir, name)\n","    if not os.path.exists(user_dir):\n","        os.makedirs(user_dir)\n","        print(f\"User '{name}' created.\")\n","\n","    userName = name\n","    signatureCount = 1  # Start with the first signature\n","\n","    display(Javascript(DRAW_JS_1))\n","    display(Javascript(DRAW_JS_2))\n","\n","# Register the add_subdir function for JavaScript to call\n","google.colab.output.register_callback('notebook.add_subdir', add_subdir)\n","\n","userreg = input(\"If you are a new user type 'y': \")\n","if userreg.lower() == 'y':\n","    name = input(\"Enter your name: \")\n","    new_user_reg(name)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":309},"id":"bZHvh2e1IQDM","executionInfo":{"status":"ok","timestamp":1720106960717,"user_tz":-330,"elapsed":10424,"user":{"displayName":"Hariharan Bhaskaran","userId":"14226885344040727414"}},"outputId":"ff3fdcae-0448-46f4-82b7-9bbf9961894c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["If you are a new user type 'y': y\n","Enter your name: Hariharan\n","User 'Hariharan' created.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","const canvas1 = document.createElement('canvas');\n","canvas1.width = 400;\n","canvas1.height = 200;\n","canvas1.style.border = '1px solid black';\n","document.body.appendChild(canvas1);\n","\n","const ctx1 = canvas1.getContext('2d');\n","ctx1.fillStyle = 'white';\n","ctx1.fillRect(0, 0, canvas1.width, canvas1.height);\n","\n","canvas1.onmousedown = function(e) {\n","  ctx1.beginPath();\n","  ctx1.moveTo(e.offsetX, e.offsetY);\n","  canvas1.onmousemove = function(e) {\n","    ctx1.lineTo(e.offsetX, e.offsetY);\n","    ctx1.stroke();\n","  };\n","};\n","\n","canvas1.onmouseup = function() {\n","  canvas1.onmousemove = null;\n","};\n","\n","const saveButton1 = document.createElement('button');\n","saveButton1.innerHTML = 'Save Signature 1';\n","saveButton1.onclick = function() {\n","  const dataURL = canvas1.toDataURL('image/png');\n","  google.colab.kernel.invokeFunction('notebook.add_subdir', [dataURL], {});\n","};\n","document.body.appendChild(saveButton1);\n"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","const canvas2 = document.createElement('canvas');\n","canvas2.width = 400;\n","canvas2.height = 200;\n","canvas2.style.border = '1px solid black';\n","document.body.appendChild(canvas2);\n","\n","const ctx2 = canvas2.getContext('2d');\n","ctx2.fillStyle = 'white';\n","ctx2.fillRect(0, 0, canvas2.width, canvas2.height);\n","\n","canvas2.onmousedown = function(e) {\n","  ctx2.beginPath();\n","  ctx2.moveTo(e.offsetX, e.offsetY);\n","  canvas2.onmousemove = function(e) {\n","    ctx2.lineTo(e.offsetX, e.offsetY);\n","    ctx2.stroke();\n","  };\n","};\n","\n","canvas2.onmouseup = function() {\n","  canvas2.onmousemove = null;\n","};\n","\n","const saveButton2 = document.createElement('button');\n","saveButton2.innerHTML = 'Save Signature 2';\n","saveButton2.onclick = function() {\n","  const dataURL = canvas2.toDataURL('image/png');\n","  google.colab.kernel.invokeFunction('notebook.add_subdir', [dataURL], {});\n","};\n","document.body.appendChild(saveButton2);\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Signature saved to /content/drive/MyDrive/Signature recognition/Hariharan/signature_1.png\n","Signature saved to /content/drive/MyDrive/Signature recognition/Hariharan/signature_2.png\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BAiVMST2LQTf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1720107424141,"user_tz":-330,"elapsed":399249,"user":{"displayName":"Hariharan Bhaskaran","userId":"14226885344040727414"}},"outputId":"a12a0c0c-398b-4e1d-d35d-5e86124f4e01"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/30\n","3/3 [==============================] - ETA: 0s - loss: 1.0249 - accuracy: 0.3182"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 13s 3s/step - loss: 1.0249 - accuracy: 0.3182 - lr: 0.0010\n","Epoch 2/30\n","3/3 [==============================] - ETA: 0s - loss: 0.8271 - accuracy: 0.6364"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 3s/step - loss: 0.8271 - accuracy: 0.6364 - lr: 0.0010\n","Epoch 3/30\n","3/3 [==============================] - ETA: 0s - loss: 0.6828 - accuracy: 0.7879"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 4s/step - loss: 0.6828 - accuracy: 0.7879 - lr: 0.0010\n","Epoch 4/30\n","3/3 [==============================] - ETA: 0s - loss: 0.6408 - accuracy: 0.7424"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 11s 3s/step - loss: 0.6408 - accuracy: 0.7424 - lr: 0.0010\n","Epoch 5/30\n","3/3 [==============================] - ETA: 0s - loss: 0.3692 - accuracy: 0.8636"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 4s/step - loss: 0.3692 - accuracy: 0.8636 - lr: 0.0010\n","Epoch 6/30\n","3/3 [==============================] - ETA: 0s - loss: 0.4649 - accuracy: 0.8333"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 11s 4s/step - loss: 0.4649 - accuracy: 0.8333 - lr: 0.0010\n","Epoch 7/30\n","3/3 [==============================] - ETA: 0s - loss: 0.4842 - accuracy: 0.8333"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 10s 3s/step - loss: 0.4842 - accuracy: 0.8333 - lr: 0.0010\n","Epoch 8/30\n","3/3 [==============================] - ETA: 0s - loss: 0.5164 - accuracy: 0.7879"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 4s/step - loss: 0.5164 - accuracy: 0.7879 - lr: 0.0010\n","Epoch 9/30\n","3/3 [==============================] - ETA: 0s - loss: 0.4456 - accuracy: 0.8485"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 4s/step - loss: 0.4456 - accuracy: 0.8485 - lr: 0.0010\n","Epoch 10/30\n","3/3 [==============================] - ETA: 0s - loss: 0.4156 - accuracy: 0.8485"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 9s 3s/step - loss: 0.4156 - accuracy: 0.8485 - lr: 0.0010\n","Epoch 11/30\n","3/3 [==============================] - ETA: 0s - loss: 0.3352 - accuracy: 0.8788"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 3s/step - loss: 0.3352 - accuracy: 0.8788 - lr: 1.0000e-04\n","Epoch 12/30\n","3/3 [==============================] - ETA: 0s - loss: 0.4620 - accuracy: 0.8333"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 4s/step - loss: 0.4620 - accuracy: 0.8333 - lr: 1.0000e-04\n","Epoch 13/30\n","3/3 [==============================] - ETA: 0s - loss: 0.2790 - accuracy: 0.9242"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 11s 4s/step - loss: 0.2790 - accuracy: 0.9242 - lr: 1.0000e-04\n","Epoch 14/30\n","3/3 [==============================] - ETA: 0s - loss: 0.2699 - accuracy: 0.8939"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 4s/step - loss: 0.2699 - accuracy: 0.8939 - lr: 1.0000e-04\n","Epoch 15/30\n","3/3 [==============================] - ETA: 0s - loss: 0.2755 - accuracy: 0.8939"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 4s/step - loss: 0.2755 - accuracy: 0.8939 - lr: 1.0000e-04\n","Epoch 16/30\n","3/3 [==============================] - ETA: 0s - loss: 0.3632 - accuracy: 0.8788"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 4s/step - loss: 0.3632 - accuracy: 0.8788 - lr: 1.0000e-04\n","Epoch 17/30\n","3/3 [==============================] - ETA: 0s - loss: 0.2756 - accuracy: 0.8939"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 4s/step - loss: 0.2756 - accuracy: 0.8939 - lr: 1.0000e-04\n","Epoch 18/30\n","3/3 [==============================] - ETA: 0s - loss: 0.2706 - accuracy: 0.9091"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 10s 3s/step - loss: 0.2706 - accuracy: 0.9091 - lr: 1.0000e-04\n","Epoch 19/30\n","3/3 [==============================] - ETA: 0s - loss: 0.2727 - accuracy: 0.9091"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 3s/step - loss: 0.2727 - accuracy: 0.9091 - lr: 1.0000e-04\n","Epoch 20/30\n","3/3 [==============================] - ETA: 0s - loss: 0.2217 - accuracy: 0.9242"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 4s/step - loss: 0.2217 - accuracy: 0.9242 - lr: 1.0000e-05\n","Epoch 21/30\n","3/3 [==============================] - ETA: 0s - loss: 0.2928 - accuracy: 0.8788"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 10s 3s/step - loss: 0.2928 - accuracy: 0.8788 - lr: 1.0000e-05\n","Epoch 22/30\n","3/3 [==============================] - ETA: 0s - loss: 0.3027 - accuracy: 0.8939"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 11s 3s/step - loss: 0.3027 - accuracy: 0.8939 - lr: 1.0000e-05\n","Epoch 23/30\n","3/3 [==============================] - ETA: 0s - loss: 0.3100 - accuracy: 0.8485"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 4s/step - loss: 0.3100 - accuracy: 0.8485 - lr: 1.0000e-05\n","Epoch 24/30\n","3/3 [==============================] - ETA: 0s - loss: 0.2699 - accuracy: 0.8939"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 9s 3s/step - loss: 0.2699 - accuracy: 0.8939 - lr: 1.0000e-05\n","Epoch 25/30\n","3/3 [==============================] - ETA: 0s - loss: 0.2673 - accuracy: 0.9091"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 3s/step - loss: 0.2673 - accuracy: 0.9091 - lr: 1.0000e-05\n","Epoch 26/30\n","3/3 [==============================] - ETA: 0s - loss: 0.2726 - accuracy: 0.9242"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 4s/step - loss: 0.2726 - accuracy: 0.9242 - lr: 1.0000e-05\n","Epoch 27/30\n","3/3 [==============================] - ETA: 0s - loss: 0.3444 - accuracy: 0.8485"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 10s 3s/step - loss: 0.3444 - accuracy: 0.8485 - lr: 1.0000e-05\n","Epoch 28/30\n","3/3 [==============================] - ETA: 0s - loss: 0.3782 - accuracy: 0.8485"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 11s 3s/step - loss: 0.3782 - accuracy: 0.8485 - lr: 1.0000e-05\n","Epoch 29/30\n","3/3 [==============================] - ETA: 0s - loss: 0.3638 - accuracy: 0.8939"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 12s 4s/step - loss: 0.3638 - accuracy: 0.8939 - lr: 1.0000e-05\n","Epoch 30/30\n","3/3 [==============================] - ETA: 0s - loss: 0.2447 - accuracy: 0.9242"]},{"output_type":"stream","name":"stderr","text":["WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n"]},{"output_type":"stream","name":"stdout","text":["\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r3/3 [==============================] - 17s 6s/step - loss: 0.2447 - accuracy: 0.9242 - lr: 1.0000e-05\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n","  saving_api.save_model(\n"]}],"source":["import os\n","import numpy as np\n","import cv2\n","from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n","\n","train_dir = '/content/drive/MyDrive/Signature recognition'\n","\n","# Image preprocessing function\n","def preprocess_image(image_path):\n","    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n","    if img is None:\n","        return None\n","    img = cv2.resize(img, (256, 256))  # Resize to a fixed size\n","    _, img = cv2.threshold(img, 127, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)  # Thresholding\n","    return img\n","\n","# Function to load and preprocess images from directory\n","def load_images_from_directory(directory):\n","    images = []\n","    labels = []\n","    for user in os.listdir(directory):\n","        user_dir = os.path.join(directory, user)\n","        if os.path.isdir(user_dir):\n","            for img_name in os.listdir(user_dir):\n","                img_path = os.path.join(user_dir, img_name)\n","                if os.path.isfile(img_path) and img_name.endswith(('.png', '.jpg', '.jpeg')):\n","                    img = preprocess_image(img_path)\n","                    if img is not None:\n","                        images.append(img)\n","                        labels.append(user)  # Assuming each user folder represents a class\n","\n","    images = np.array(images)\n","    labels = np.array(labels)\n","    return images, labels\n","\n","# Load and preprocess images\n","images, labels = load_images_from_directory(train_dir)\n","\n","# Reshape images to add channel dimension\n","images = images.reshape(images.shape[0], 256, 256, 1).astype('float32') / 255.0\n","\n","# Encode labels as integers\n","from sklearn.preprocessing import LabelEncoder\n","label_encoder = LabelEncoder()\n","labels_encoded = label_encoder.fit_transform(labels)\n","\n","# Convert labels to categorical format\n","from tensorflow.keras.utils import to_categorical\n","labels_categorical = to_categorical(labels_encoded)\n","\n","# Data augmentation generator\n","datagen = ImageDataGenerator(\n","    rotation_range=10,\n","    width_shift_range=0.1,\n","    height_shift_range=0.1,\n","    shear_range=0.1,\n","    zoom_range=0.1,\n","    fill_mode='nearest'\n",")\n","\n","# Define model architecture\n","model = Sequential([\n","    Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(64, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(128, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Conv2D(256, (3, 3), activation='relu'),\n","    MaxPooling2D((2, 2)),\n","    Flatten(),\n","    Dense(128, activation='relu'),\n","    Dropout(0.5),\n","    Dense(64, activation='relu'),\n","    Dense(len(np.unique(labels)), activation='softmax')  # Output has as many classes as there are users\n","])\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","# Callbacks for early stopping, saving the best model, and reducing learning rate on plateau\n","early_stopping = EarlyStopping(monitor='loss', patience=10, restore_best_weights=True)\n","model_checkpoint = ModelCheckpoint('best_signature_model.h5', save_best_only=True)\n","reduce_lr = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=5, min_lr=0.00001)\n","\n","# Train the model with data augmentation\n","model.fit(\n","    datagen.flow(images, labels_categorical, batch_size=22),\n","    epochs=len(os.listdir(train_dir) * 10),\n","    callbacks=[early_stopping, model_checkpoint, reduce_lr]\n",")\n","\n","# Save the trained model\n","model.save('final_signature_model.h5')\n"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"dsG3X3GiK4pG","colab":{"base_uri":"https://localhost:8080/","height":326},"executionInfo":{"status":"ok","timestamp":1720108463838,"user_tz":-330,"elapsed":1245,"user":{"displayName":"Hariharan Bhaskaran","userId":"14226885344040727414"}},"outputId":"10fba690-7433-45b0-d6f0-31a1c32a15fb"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","const canvas = document.createElement('canvas');\n","canvas.width = 400;\n","canvas.height = 200;\n","canvas.style.border = '1px solid black';\n","document.body.appendChild(canvas);\n","\n","const ctx = canvas.getContext('2d');\n","ctx.fillStyle = 'white';\n","ctx.fillRect(0, 0, canvas.width, canvas.height);\n","\n","canvas.onmousedown = function(e) {\n","  ctx.beginPath();\n","  ctx.moveTo(e.offsetX, e.offsetY);\n","  canvas.onmousemove = function(e) {\n","    ctx.lineTo(e.offsetX, e.offsetY);\n","    ctx.stroke();\n","  };\n","};\n","\n","canvas.onmouseup = function() {\n","  canvas.onmousemove = null;\n","};\n","\n","const predictButton = document.createElement('button');\n","predictButton.innerHTML = 'Predict';\n","predictButton.onclick = function() {\n","  const dataURL = canvas.toDataURL('image/png');\n","  google.colab.kernel.invokeFunction('notebook.predict', [dataURL], {});\n","};\n","document.body.appendChild(predictButton);\n","\n","const clearButton = document.createElement('button');\n","clearButton.innerHTML = 'Clear';\n","clearButton.onclick = function() {\n","  ctx.clearRect(0, 0, canvas.width, canvas.height);\n","};\n","document.body.appendChild(clearButton);\n"]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Image array shape: (1, 256, 256, 1)\n","1/1 [==============================] - 0s 144ms/step\n","Probabilities: [0.29966864 0.07900655 0.6213248 ], Max Probability: 0.6213247776031494, RMSE: 0.5213511809304071\n","Predicted User: Stranger\n","Probabilities: [0.29966864 0.07900655 0.6213248 ]\n","RMSE: 0.5213511809304071\n"]}],"source":["import base64\n","import io\n","import numpy as np\n","from PIL import Image\n","from tensorflow.keras.models import load_model\n","from google.colab import output\n","from IPython.display import display, Javascript\n","\n","# Load your handwriting recognition model\n","model = load_model('/content/final_signature_model.h5')\n","\n","# Define user names\n","user_names = os.listdir(train_dir)\n","stranger_threshold = 0.75  # Threshold for recognizing a stranger\n","\n","# JavaScript to create a canvas and capture the image\n","DRAW_JS = \"\"\"\n","const canvas = document.createElement('canvas');\n","canvas.width = 400;\n","canvas.height = 200;\n","canvas.style.border = '1px solid black';\n","document.body.appendChild(canvas);\n","\n","const ctx = canvas.getContext('2d');\n","ctx.fillStyle = 'white';\n","ctx.fillRect(0, 0, canvas.width, canvas.height);\n","\n","canvas.onmousedown = function(e) {\n","  ctx.beginPath();\n","  ctx.moveTo(e.offsetX, e.offsetY);\n","  canvas.onmousemove = function(e) {\n","    ctx.lineTo(e.offsetX, e.offsetY);\n","    ctx.stroke();\n","  };\n","};\n","\n","canvas.onmouseup = function() {\n","  canvas.onmousemove = null;\n","};\n","\n","const predictButton = document.createElement('button');\n","predictButton.innerHTML = 'Predict';\n","predictButton.onclick = function() {\n","  const dataURL = canvas.toDataURL('image/png');\n","  google.colab.kernel.invokeFunction('notebook.predict', [dataURL], {});\n","};\n","document.body.appendChild(predictButton);\n","\n","const clearButton = document.createElement('button');\n","clearButton.innerHTML = 'Clear';\n","clearButton.onclick = function() {\n","  ctx.clearRect(0, 0, canvas.width, canvas.height);\n","};\n","document.body.appendChild(clearButton);\n","\"\"\"\n","\n","# Function to preprocess the image\n","def preprocess_image(image_data):\n","    image = Image.open(io.BytesIO(image_data))\n","    image = image.convert('L')  # Convert to grayscale\n","    image = image.resize((256, 256))  # Resize to model input size\n","    img_array = np.array(image) / 255.0  # Normalize to [0, 1]\n","    img_array = np.expand_dims(img_array, axis=(0, -1))  # Add batch and channel dimensions\n","    return img_array\n","\n","# Function to predict user and calculate probabilities and RMSE\n","def predict_user(img_array, user_names, model):\n","    prediction = model.predict(img_array)\n","    probabilities = prediction[0]\n","    rmse = np.sqrt(np.mean(np.square(prediction - np.eye(len(user_names)))))\n","    max_prob = np.max(probabilities)\n","    print(f\"Probabilities: {probabilities}, Max Probability: {max_prob}, RMSE: {rmse}\")\n","    if max_prob < stranger_threshold:\n","        return 'Stranger', probabilities, rmse\n","    predicted_user_index = np.argmax(probabilities)\n","    return user_names[predicted_user_index], probabilities, rmse\n","\n","# Function to handle the prediction process\n","def predict_signature(image_data_url):\n","    image_data = base64.b64decode(image_data_url.split(',')[1])\n","    img_array = preprocess_image(image_data)\n","    print(f\"Image array shape: {img_array.shape}\")\n","    predicted_user, probabilities, rmse = predict_user(img_array, user_names, model)\n","    print(f\"Predicted User: {predicted_user}\")\n","    print(f\"Probabilities: {probabilities}\")\n","    print(f\"RMSE: {rmse}\")\n","    return predicted_user, probabilities, rmse\n","\n","output.register_callback('notebook.predict', predict_signature)\n","\n","# Display the drawing canvas and buttons\n","display(Javascript(DRAW_JS))\n"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","# Function to plot images in a grid\n","def plot_images(images_arr, n_images=4):\n","    fig, axes = plt.subplots(1, n_images, figsize=(20,20))\n","    axes = axes.flatten()\n","    for img, ax in zip(images_arr, axes):\n","        ax.imshow(img[:,:,0], cmap='gray')\n","        ax.axis('off')\n","    plt.tight_layout()\n","    plt.show()\n","\n","# Get a batch of augmented images\n","augmented_images, _ = next(train_generator)\n","\n","# Plot the images\n","plot_images(augmented_images)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":219},"id":"9kk7Q-TLSvRw","executionInfo":{"status":"error","timestamp":1720105115873,"user_tz":-330,"elapsed":426,"user":{"displayName":"Baranidharan Selvaraj","userId":"02715916236001269930"}},"outputId":"67a43c11-66d6-44d0-9ff8-a267dcba31ba"},"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'train_generator' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-42d10800e9b9>\u001b[0m in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Get a batch of augmented images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0maugmented_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m# Plot the images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"]}]},{"cell_type":"code","source":[],"metadata":{"id":"x7AlssT_QRye"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[{"file_id":"1_2m4NWwHdmCdFiHgYn-VWcxGpc7Jr9ak","timestamp":1701869290378},{"file_id":"1SX2x26D-OJcjCTlQehyOYzBEsJWPNG-8","timestamp":1701683672505},{"file_id":"1yuTEB4jOnMC-VNxsespkowtNDG6PHtwS","timestamp":1701368563050}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}